{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['database', 'mlflow', 'font']\n",
      "/media/myungsungkwak/msdisk/docrv2_sroie/modules/database/\n",
      "/media/myungsungkwak/msdisk/docrv2_data/DB/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from configparser import ConfigParser\n",
    "path_config_file = os.getcwd().split('docrv2_sroie')[0] + 'docrv2_sroie/' + 'config.ini'\n",
    "common_variable = ConfigParser()\n",
    "common_variable.read(path_config_file)\n",
    "\n",
    "print(common_variable.sections())\n",
    "print(common_variable['database']['module_path'])\n",
    "print(common_variable['database']['DB_BASE'])\n",
    "\n",
    "import sys\n",
    "sys.path.append(common_variable['database']['module_path'])\n",
    "from db_util import *\n",
    "from db import *\n",
    "\n",
    "import tensorflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "\n",
    "from parse import parse\n",
    "from PIL import Image, ImageFont, ImageDraw, ImageEnhance\n",
    "from glob import glob\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------------------------------------------------------+\n",
      "| Key         | Value                                                    |\n",
      "+-------------+----------------------------------------------------------+\n",
      "| class       | train                                                    |\n",
      "| created     | 2020-09-14 10:36:48                                      |\n",
      "| db_data     | (database)                                               |\n",
      "| description | datadb_d2gan, resized to 1/2, random crop, 50im per data |\n",
      "| name        | d2gan_raw_training_halfsizev2                            |\n",
      "| note        |                                                          |\n",
      "| reference   | /home/dk/docrv2_sroie/DB/d2gan_raw_training_halfsizev2   |\n",
      "| sep         | \t                                                        |\n",
      "| updated     | 2020-09-14 10:36:48                                      |\n",
      "+-------------+----------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "check_db_name = \"d2gan_raw_training_halfsizev2\"\n",
    "check_db_path = common_variable['database']['DB_BASE']\n",
    "check_db = open_env(os.path.join(check_db_path, check_db_name))\n",
    "print_env(check_db)\n",
    "#check_imgs = read_bulk_data_from_db(check_db, prefix='img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache={}\n",
    "cache[b'reference'] = str(os.path.join(check_db_path, check_db_name)).encode()\n",
    "write_cache_to_env(check_db, cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------------------------------------------------------------+\n",
      "| Key         | Value                                                                    |\n",
      "+-------------+--------------------------------------------------------------------------+\n",
      "| class       | train                                                                    |\n",
      "| created     | 2020-09-14 10:36:48                                                      |\n",
      "| db_data     | (database)                                                               |\n",
      "| description | datadb_d2gan, resized to 1/2, random crop, 50im per data                 |\n",
      "| name        | d2gan_raw_training_halfsizev2                                            |\n",
      "| note        |                                                                          |\n",
      "| reference   | /media/myungsungkwak/msdisk/docrv2_data/DB/d2gan_raw_training_halfsizev2 |\n",
      "| sep         | \t                                                                        |\n",
      "| updated     | 2020-09-14 10:36:48                                                      |\n",
      "+-------------+--------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "print_env(check_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_database(db_idx, db_name=None):\n",
    "    path = common_variable['database']['DB_BASE']\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "    name = db_name + \"_%04d\"%db_idx\n",
    "    description = 'data db from train_task2 all coords images'\n",
    "    datadb = create_data_db(path=path, name=name, description=description, data_class='DATA')\n",
    "    print(\"... created db : \", name)\n",
    "    return datadb\n",
    "\n",
    "def update_database(datadb, imgs, coords, refname, db_start_idx):\n",
    "\n",
    "    for idx, img in enumerate(imgs):\n",
    "        chars = []\n",
    "        transpose_chars = np.transpose(coords[idx])[8]\n",
    "        transpose_chars = list(map(str, transpose_chars))\n",
    "        chars.append(transpose_chars)\n",
    "\n",
    "\n",
    "        char_table = pd.DataFrame(coords[idx])\n",
    "        char_table.rename(columns={0:'x1', 1:'y1', 2:'x2', 3:'y2', 4:'x3',\n",
    "                                   5:'y3', 6:'x4', 7:'y4', 8:'char'}, inplace=True)\n",
    "        char_table.x1 = char_table.x1.astype(int)\n",
    "        char_table.y1 = char_table.y1.astype(int)\n",
    "        char_table.x2 = char_table.x2.astype(int)\n",
    "        char_table.y2 = char_table.y2.astype(int)\n",
    "        char_table.x3 = char_table.x3.astype(int)\n",
    "        char_table.y3 = char_table.y3.astype(int)\n",
    "        char_table.x4 = char_table.x4.astype(int)\n",
    "        char_table.y4 = char_table.y4.astype(int)\n",
    "        \n",
    "        update_data(datadb, \n",
    "                    index=db_start_idx+idx, \n",
    "                    label='task12', \n",
    "                    image=img, \n",
    "                    text=None, \n",
    "                    ref=refname, \n",
    "                    char_c=char_table,\n",
    "                    char=chars[0])\n",
    "\n",
    "def get_coords_from_image(txt_file):\n",
    "    lps = []\n",
    "\n",
    "    try:\n",
    "        with open(txt_file, 'r') as f:\n",
    "            coords_data = f.read().split('\\n')\n",
    "            for ii in range(len(coords_data)):\n",
    "                if len(coords_data[ii]) > 0:\n",
    "                    ps = parse('{},{},{},{},{},{},{},{},{}', coords_data[ii])\n",
    "                    ps = list(ps)\n",
    "                    ps[:-1] = list(map(int, ps[:-1]))\n",
    "                    lps.append(ps)\n",
    "    except:\n",
    "        with open(txt_file, 'r', encoding='ISO-8859-1') as f:\n",
    "            coords_data = f.read().split('\\n')\n",
    "            for ii in range(len(coords_data)):\n",
    "                if len(coords_data[ii]) > 0:\n",
    "                    ps = parse('{},{},{},{},{},{},{},{},{}', coords_data[ii])\n",
    "                    ps = list(ps)\n",
    "                    ps[:-1] = list(map(int, ps[:-1]))\n",
    "                    lps.append(ps)\n",
    "    return lps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "method 1 - no padding\n",
    "crop images followed as original x1 coordiantes (x1 random choice)\n",
    "crop size 256, 128\n",
    "\"\"\"\n",
    "\n",
    "def get_crop_image(img_path, coords, crop_size=(256,128), num_images=1):\n",
    "    \n",
    "    img = Image.open(img_path)\n",
    "    o_width = img.size[0]\n",
    "    o_height = img.size[1]\n",
    "\n",
    "    transpose_x1_coords = np.transpose(coords)[0]\n",
    "    transpose_y1_coords = np.transpose(coords)[1]\n",
    "    transpose_x1_coords = list(map(int, transpose_x1_coords)) \n",
    "    transpose_y1_coords = list(map(int, transpose_y1_coords)) \n",
    "\n",
    "    sample_list = []\n",
    "    coords_list = []\n",
    "    for idx in range(num_images):\n",
    "        while True:\n",
    "            # base_idx = idx # (all x1 coords)\n",
    "            base_idx = np.random.choice(len(transpose_x1_coords), 1, replace=False)[0]\n",
    "            \n",
    "            base_x1 = transpose_x1_coords[base_idx]\n",
    "            base_y1 = transpose_y1_coords[base_idx]\n",
    "\n",
    "            new_x3 = base_x1 + crop_size[0]\n",
    "            new_y3 = base_y1 + crop_size[1]\n",
    "\n",
    "            if (new_x3 > o_width) or (new_y3 > o_height):\n",
    "                continue\n",
    "            crop_img = img.crop((base_x1, base_y1, new_x3, new_y3))\n",
    "            copy_coords = copy.deepcopy(coords)\n",
    "            crop_coords = calculate_coords(copy_coords, base_idx, (base_x1, base_y1))\n",
    "            \n",
    "            coords_list.append(crop_coords)\n",
    "            sample_list.append(crop_img)\n",
    "            del crop_coords[:][:]\n",
    "            break\n",
    "    return sample_list, coords_list, base_idx, (base_x1,base_y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "method 2 - random padding\n",
    "crop size 256, 128\n",
    "\"\"\"\n",
    "def get_crop_image_by_coords_pad_random(img_path, coords, crop_size=(256,128), num_images=1):\n",
    "    \n",
    "    img = Image.open(img_path)\n",
    "    \n",
    "    o_width = img.size[0]\n",
    "    o_height = img.size[1]\n",
    "\n",
    "    transpose_x1_coords = np.transpose(coords)[0]\n",
    "    transpose_y1_coords = np.transpose(coords)[1]\n",
    "    transpose_x1_coords = list(map(int, transpose_x1_coords)) \n",
    "    transpose_y1_coords = list(map(int, transpose_y1_coords))\n",
    "    \n",
    "    transpose_x2_coords = np.transpose(coords)[2]\n",
    "    transpose_y2_coords = np.transpose(coords)[3]\n",
    "    transpose_x2_coords = list(map(int, transpose_x2_coords))\n",
    "    transpose_y2_coords = list(map(int, transpose_y2_coords))\n",
    "\n",
    "    transpose_x3_coords = np.transpose(coords)[4]\n",
    "    transpose_y3_coords = np.transpose(coords)[5]\n",
    "    transpose_x3_coords = list(map(int, transpose_x3_coords))\n",
    "    transpose_y3_coords = list(map(int, transpose_y3_coords))\n",
    "\n",
    "    transpose_x4_coords = np.transpose(coords)[6]\n",
    "    transpose_y4_coords = np.transpose(coords)[7]\n",
    "    transpose_x4_coords = list(map(int, transpose_x4_coords))\n",
    "    transpose_y4_coords = list(map(int, transpose_y4_coords))\n",
    "\n",
    "    transpose_chars = np.transpose(coords)[8]\n",
    "\n",
    "    sample_list = []\n",
    "    coords_list = []\n",
    "    img_cnt = 0\n",
    "    \n",
    "    for _ in range(np.random.randint(1, 10)):\n",
    "        # num of coords\n",
    "        for idx in range(num_images):\n",
    "            while True:\n",
    "                base_idx = idx\n",
    "                pdd = np.random.randint(-5,10,2) # [x1, y1]\n",
    "                \n",
    "                base_x1 = transpose_x1_coords[base_idx]\n",
    "                base_y1 = transpose_y1_coords[base_idx]\n",
    "                \n",
    "                new_x1 = base_x1 - pdd[0]\n",
    "                new_y1 = base_y1 - pdd[1]\n",
    "                new_x3 = base_x1 + crop_size[0] - pdd[0]\n",
    "                new_y3 = base_y1 + crop_size[1] - pdd[1]\n",
    "                \n",
    "                if (new_x1 < 0) or (new_y1 < 0):\n",
    "                    continue\n",
    "                if (new_x3 > o_width) or (new_y3 > o_height):\n",
    "                    if (base_x1 + crop_size[0]) > o_width or (base_y1 + crop_size[1]) > o_height:\n",
    "                        break\n",
    "                    else:\n",
    "                        continue\n",
    "\n",
    "                crop_img = img.crop((new_x1, new_y1, new_x3, new_y3))\n",
    "                #print(\"- {}, {}, pdd: {} --> {}\".format(idx, crop_img.size, pdd, transpose_chars[idx]))\n",
    "\n",
    "                copy_coords = copy.deepcopy(coords)\n",
    "                crop_coords = calculate_coords(copy_coords, base_idx, (new_x1, new_y1), pdd=(pdd[0],pdd[1]))\n",
    "\n",
    "                coords_list.append(crop_coords)\n",
    "                sample_list.append(crop_img)\n",
    "\n",
    "                img_cnt = img_cnt +1\n",
    "\n",
    "                del crop_coords[:][:]\n",
    "                break\n",
    "    return sample_list, coords_list, img_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "run1: no padding (use get_crop_image)\n",
    "\"\"\"\n",
    "datadir = '/media/myungsungkwak/msdisk/docrv2_sroie/data/train_task1_crop/'\n",
    "img_files = glob(datadir+'*.jpg')\n",
    "txt_files = glob(datadir+'*.txt')\n",
    "\n",
    "crop_images = []\n",
    "coords_table = []\n",
    "\n",
    "print(len(img_files))\n",
    "\n",
    "datadb = create_database(100, \"d2gan_train_all\")\n",
    "num_images = 5\n",
    "db_start_idx = 0\n",
    "#for idx in tqdm(range(len(img_files))):\n",
    "for idx in tqdm(range(2)):\n",
    "    # print(idx, \" : \", img_files[idx])\n",
    "    refname = os.path.basename(img_files[idx])[:-4]\n",
    "    txt_filepath = os.path.join(datadir, refname+'.txt')\n",
    "    coords_table.append(get_coords_from_image(txt_filepath))\n",
    "    crop_img, crop_coords, crop_idx, crop_xy = get_crop_image(img_files[idx],\n",
    "                                                              coords_table[idx],\n",
    "                                                              crop_size=(256,128),\n",
    "                                                              num_images=num_images)\n",
    "    update_database(datadb, crop_img, crop_coords, refname, db_start_idx)\n",
    "    db_start_idx = db_start_idx + num_images\n",
    "    \n",
    "    del coords_table[:][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "run2: random padding (use get_crop_image_by_coords_pad_random)\n",
    "\"\"\"\n",
    "\n",
    "# datadir = '/media/myungsungkwak/msdisk/docrv2_sroie/data/train_task1_crop/'\n",
    "for folder_idx in range(4):\n",
    "    \n",
    "#     datadir = '/data/raw_data/train_task1_crop_split_sample_{}/'.format(folder_idx+1)\n",
    "    datadir = '/data/raw_data/train_task1_crop_split_{}/'.format(folder_idx+1)\n",
    "    print(\"[\" + datadir + \"]\")\n",
    "    \n",
    "    img_files = glob(datadir+'*.jpg')\n",
    "    txt_files = glob(datadir+'*.txt')\n",
    "\n",
    "    crop_images = []\n",
    "    coords_table = []\n",
    "\n",
    "    datadb = create_database(folder_idx+1, \"d2gan_train_task1_random_pad_sp\")\n",
    "    \n",
    "    num_images = 1\n",
    "    db_start_idx = 0\n",
    "    for idx in range(len(img_files)):\n",
    "        \n",
    "        refname = os.path.basename(img_files[idx])[:-4]\n",
    "        txt_filepath = os.path.join(datadir, refname+'.txt')\n",
    "        \n",
    "        coords_table.append(get_coords_from_image(txt_filepath))\n",
    "        \n",
    "        print(\"{}. {}\".format(idx, img_files[idx]))\n",
    "        print(\"{}. {}\".format(idx, txt_filepath))\n",
    "        \n",
    "        num_images = len(coords_table[idx])\n",
    "        crop_img, crop_coords, img_cnt = get_crop_image_by_coords_pad_random(img_files[idx],\n",
    "                                                                             coords_table[idx],\n",
    "                                                                             crop_size=(256,128),\n",
    "                                                                             num_images=num_images\n",
    "                                                                            )\n",
    "        print(\"- orig imgs : {}, len(crimg) : {}, created imgs : {}, start_db_idx : {}, end_db_idx : {}\".format(\n",
    "            num_images,\n",
    "            len(crop_img),\n",
    "            img_cnt,\n",
    "            db_start_idx,\n",
    "            db_start_idx+img_cnt))\n",
    "\n",
    "        update_database(datadb, crop_img, crop_coords, refname, db_start_idx)\n",
    "        db_start_idx = db_start_idx + img_cnt\n",
    "\n",
    "        del coords_table[:][:]\n",
    "    print(\"********** complete {}\".format(datadir))\n",
    "print(\"...complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "check heatmap\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "methods in D2GAN\n",
    "\"\"\"\n",
    "import cv2\n",
    "def get_gaussian1d_heatmap(size=512, distanceRatio=1.5):\n",
    "    # 1d gaussian heatmap along x axis\n",
    "    v = np.abs(np.linspace(-size / 2, size / 2, num=size))\n",
    "    x, y = np.meshgrid(v, v)\n",
    "    g = np.sqrt(y ** 2)\n",
    "    g *= distanceRatio / (size / 2)\n",
    "    g = np.exp(-(1 / 2) * (g ** 2))\n",
    "    g *= 255\n",
    "    return g.clip(0, 255)\n",
    "\n",
    "def compute_word_maps_no_space(heatmap, image_height, image_width, lines, descale=2, shiftx=0, shifty=0, paddx=0, paddy=0):\n",
    "\n",
    "    textmap = np.zeros((image_height // descale, image_width // descale)).astype('float32')\n",
    "\n",
    "    src = np.array([[0, 0], [heatmap.shape[1], 0], [heatmap.shape[1], heatmap.shape[0]], [0, heatmap.shape[0]]]).astype(\n",
    "        'float32')\n",
    "\n",
    "    for line in lines:\n",
    "        for lind in range(len(line)):\n",
    "            lvals = line[lind]\n",
    "            x1 = lvals[0] - paddx - shiftx\n",
    "            y1 = lvals[1] - paddy - shifty\n",
    "\n",
    "            x2 = lvals[2] + paddx - shiftx\n",
    "            y2 = lvals[3] - paddy - shifty\n",
    "\n",
    "            x3 = lvals[4] + paddx - shiftx\n",
    "            y3 = lvals[5] + paddy - shifty\n",
    "\n",
    "            x4 = lvals[6] - paddx - shiftx\n",
    "            y4 = lvals[7] + paddy - shifty\n",
    "            c = lvals[8]\n",
    "\n",
    "            character_points = np.array([[x1, y1], [x2, y2], [x3, y3], [x4, y4]]).astype(\n",
    "                'float32') / descale\n",
    "\n",
    "            MA = cv2.getPerspectiveTransform(\n",
    "                src=src,\n",
    "                dst=character_points,\n",
    "            )\n",
    "\n",
    "            textmap += cv2.warpPerspective(heatmap, MA, dsize=(textmap.shape[1], textmap.shape[0])).astype(\n",
    "                'float32')\n",
    "\n",
    "    emptymap = np.zeros(textmap.shape)\n",
    "    return np.concatenate([textmap[..., np.newaxis], emptymap[..., np.newaxis], emptymap[..., np.newaxis]],\n",
    "                            axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images_in_db(db_name,\n",
    "                      db_base=common_variable['database']['DB_BASE'],\n",
    "                      prefix='img',\n",
    "                      show_imgs_count=10,\n",
    "                      enable_db_info=False):\n",
    "    target_db_path = os.path.join(db_base, db_name)\n",
    "    target_db = open_env(target_db_path)\n",
    "\n",
    "    if enable_db_info:\n",
    "        print_env(target_db)\n",
    "        print_db(target_db)\n",
    "\n",
    "    imgs = read_bulk_data_from_db(target_db, prefix='img')\n",
    "    imgs_len = len(imgs)\n",
    "    # or\n",
    "    # imgs_length = show_imgs_count\n",
    "\n",
    "    rows = 5\n",
    "    cols = 5\n",
    "    axes = []\n",
    "    fig = plt.figure(figsize=(30,30))\n",
    "    \n",
    "    idx = 0\n",
    "    for idx in range(imgs_len):\n",
    "        axes.append(fig.add_subplot(rows, cols, idx+1))\n",
    "        plt.axis('off')\n",
    "        plt.imshow(imgs[idx])\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "check map images\n",
    "\"\"\"\n",
    "datadb = open_env(path=common_variable['database']['DB_BASE'] + 'd2gan_train_task1_random_pad_sample_0001')\n",
    "imgs = read_bulk_data_from_db(datadb, prefix='img')\n",
    "char_c = read_bulk_data_from_db(datadb, prefix='char_c')\n",
    "# print_db(datadb)\n",
    "\n",
    "\"\"\"\n",
    "show 10 images\n",
    "\"\"\"\n",
    "vimgs = []\n",
    "for index in range(len(imgs)):\n",
    "    img_size = imgs[index].size\n",
    "    heatmap = get_gaussian1d_heatmap(distanceRatio=1.5)\n",
    "    lines = char_c[index]\n",
    "    for idx in range(len(lines)):\n",
    "        lines[idx][0:8] = list(map(int, lines[idx][0:8]))\n",
    "    mapimg = compute_word_maps_no_space(heatmap, img_size[1], img_size[0], [lines], descale=2)\n",
    "    \n",
    "    vimgs.append(imgs[index])\n",
    "    vimgs.append(mapimg)\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(15, 15))\n",
    "columns = 4\n",
    "rows = 5\n",
    "ax = []\n",
    "for index in range(columns*rows):\n",
    "    ax.append(fig.add_subplot(rows, columns, index+1) )\n",
    "    ax[-1].set_title(\"index : \"+str(index))\n",
    "    plt.imshow(vimgs[index])\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
